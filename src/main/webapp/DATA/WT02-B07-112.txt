
<DOC>
<DOCNO>WT02-B07-112</DOCNO>
<DOCOLDNO>IA095-001027-B012-9</DOCOLDNO>
<DOCHDR>
http://www.cdt.org:80/publications/ftc_xprivacy_112095.html 205.177.10.31 19970215011913 text/html 32943
HTTP/1.0 200 OK
Date: Sat, 15 Feb 1997 01:17:52 GMT
Server: Apache/1.1.1
Content-type: text/html
</DOCHDR>
<html>
<head>
<title>PRIVACY AND INDIVIDUAL EMPOWERMENT IN THE INTERACTIVE AGE</title>
</head>
<body>
<p>
<p>
<center><h2> Privacy And Individual Empowerment<br> 
In The Interactive Age</h2></center>
<p>
<font size = +1>
<p>
<p>
<h3>I.  LANDSCAPE</h3>
<p>
The era we have come to characterize as the "Information Age" is 
evolving into the "Interactive Age." The communications technologies that 
made possible the collection, storage, transmission, and linkage of enormous 
amounts of information are now expanding to engage the individual consumer  in a variety of activities. More and more people are communicating by electronic mail; sites on the World Wide Web allow people to "browse,"  download information, and get linked to other sites; electronic malls invite people to window shop, inquire further about particular products and even  make purchases; people are subscribing to newsgroups and participating in chatrooms to gather and share information on topics of interest to them. 
<p>	
The potential benefits to society from these new digital media are 
undisputed and well-documented.  Freedom of speech and the right to receive information may enjoy a nearly limitless opportunity to flourish.  The commercial potential of the Internet is also vast.  What is troubling, however, is that this same technology makes it possible to generate, capture, store, and reuse a tremendous amount of personal transactional information and communications from diverse media, over the course of  a person's lifetime.  The "womb-to-tomb dossier" that Arthur Miller warned of 30 years ago may now be real -- not collected in a mainframe computer, but through a 
distributed and largely unregulated network. 
<p>
More focused attention is being paid to addressing the privacy issues 
that threaten to undermine substantially both the First Amendment and the 
commercial potential of the Interactive Age,  yet few concrete solutions have 
been proposed.  While there seems to be general agreement that individual 
privacy must be preserved, and even enhanced, in cyberspace, we are just 
beginning to explore the means to make privacy work in this new media. 1  
The recent deliberations, by both the government and the private sector, come at a time of increasing public concern with the loss of privacy.  A recent 
survey revealed that 83% of Americans are very concerned about their 
privacy.  This number has increased steadily over the years.  A finding of 
even greater importance in our "Interactive Age," is that the publics' concern 
with privacy reaches new heights when computerization is mentioned.   
<p>
Disquieting fear and confusion over the lack of privacy rules and 
standards act as a barrier to the public's willingness to use new media.   As 
information about the current practices of collecting and using personal 
information trickles out in news stories and in on-line discussion groups 
public concern will escalate.  The recent revelation that a marketer was 
gathering hundreds of thousands of individuals' email addresses culled from 
use of the World Wide Web and usenet discussion groups, created a furor over  the use of this transaction data.2
<p>	
A dialogue must occur between privacy and consumer advocates, and 
the private sector, before privacy policies and practices can be identified.  
Once identified, privacy policies and practices can guide and influence the 
development and deployment of new technologies to our collective benefit.   
<p>
A consensus emerged last year among policy makers, businesses, and 
privacy advocates that personally identifiable transaction data deserves 
strong legal protection, akin to the protections we afford content.3  However, 
the consensus centered on limiting law enforcement access to transaction data, and failed to address the significant privacy issues posed by the private 
sector's use of this identifiable data.  Before people will fully and openly take 
advantage of the new communications technologies and applications, they 
must have trust and confidence that their expectations of privacy and security 
are not undermined.  As John Markoff concluded in the New York Times  last month, "The recent rush to the Internet by companies seeking to exploit its commercial possibilities has obscured the fact that giving the system a new 
purpose has unearthed fundamental problems that could well put off true 
commercial viability for years."4  A recent poll conducted for CommerceNet 
found that even though Internet use is growing, "a wide variety of businesses 
selling goods on the Internet have been disappointed so far, hindered by 
security issues and a cautious attitude about commerce on the Internet among 
consumers.
<p>
We must seize the opportunity to move beyond the current debate over 
the intrusive nature of technology to embrace the technology's capacity to 
empower individuals to exercise meaningful choice over  the disclosure and 
use of personal information.  In the traditional information privacy realm, 
various interests have wrestled with awkward, mechanistic, and largely 
unsuccessful approaches to allowing people some say over how and whether 
their personal information should be used by others.  We debate the merits of 
"opt-in" over "opt-out," and how to categorize "sensitive" information.  We 
argue over who "owns" information, and whether one is a privacy 
"fundamentalist" or a privacy "pragmatist."  Essentially, privacy and consumer advocates have been engaged in a tug of war with the communications and information industries for control over personal information. 
<p>
This is not to say that these "tugs" have not produced results that 
benefit privacy and free speech, as well as commerce.5  However, interactivity 
provides us with the opportunity to fashion a truer privacy paradigm that 
promotes individual choice and empowerment, robust speech, more secure 
communications and transactions, and vigorous commerce.  For instance, 
interactivity makes possible real-time notice and choice options that 
acknowledge a direct relationship between individuals and the companies 
with which they do business.  Notice and choice options can be presented at 
varying levels of granularity, depending on the individual's desire at the time of a particular transaction.  Interactions can once again be tailored by and for the individual.  
<p>
As the recent Department of Commerce report, "Privacy and the NII: 
Safeguarding Telecommunications-Related Personal Information," concluded:  
<blockquote>"The promised interactivity of the NII may diminish the need to make a policy choice between opt-in and opt-out. Such interactivity would make it possible for service providers to obtain consent to use [transaction-related personal information] from subscribers electronically before any services were rendered."6</blockquote>
<p> 
Today, the privacy potential of interactive technology remains 
largely hidden and untapped.   Unique facets of this new medium can be bent 
to advance privacy and encourage full and open participation.   A range of 
policy and technical options will be discussed in greater detail in the "New 
Privacy Paradigm" section of this paper. 
<p>
<h3>II.  WHY IS PRIVACY IMPORTANT?</h3>
<p>
Before launching into a discussion of privacy, we must begin by defining 
the term.  The difficulty of defining privacy and its underlying principles has 
stymied and paralyzed policy makers and philosophers.  One privacy scholar 
who has written on privacy issues for decades resorted to defining it in these 
visceral terms: "You know it when you lose it." 7  Yet defining privacy and its 
value to individuals and society is essential if we are to develop cohesive, 
rational information privacy policies.  We must understand why preserving 
and enhancing privacy is an ultimate "good" before we can expect policy 
makers, the private sector, and privacy and consumer advocates to reach 
some common ground on core privacy principles and their application.
<p>
Information privacy is defined here as incorporating two components, at 
times distinct and at times inextricable.  The first component is the right to 
retreat from the world; one's family, neighbors, community, and government.  This component allows us to shield ourselves, physically and psychologically, from the prying eyes of others. We think of this privacy value, as it was initially described by Justice Louis Brandeis over a century ago, as "the right to be let alone." 
<p>
The second component of privacy is the right to control information 
about oneself, even after divulging it to others.  This component acknowledges the critical value of being able to step forward and participate in society without having to relinquish all control over personal information.  As Professor Alan Westin first defined it in Privacy and Freedom, to  maintain privacy in modern times, individuals need to "determine for one's self when, how, and to what extent information about one's self is communicated to others."8  
<p>
Privacy as defined here allows individuals to choose when to withdraw 
and when to participate.  People must be able to seek solitude and isolation 
from others to develop a sense of one's self apart from others.  Developing 
one's unique identity is critical to a person's ability to form his or her own 
thoughts and opinions, and to establish intimate connections with others.  A 
society that preserves privacy for its people is one that acknowledges the 
individual's interest in maintaining control over his or her life.  One aspect of this control is being able to determine the presentation of one's self, or various pieces of one's self, to others.  A person who is unable to truly retreat feels constantly watched, dehumanized, and powerless to make fundamental 
decisions affecting his or her life.9  Equally important to having the capacity to retreat from society, is having the ability to step forward to participate in the affairs of society.  It is axiomatic that an individual's willingness to engage in the activities of the community will be tempered by the degree to which he or  she is able to maintain control over the development and presentation of one's self.10  In the absence of control over the development of one's self, individual autonomy and self-determination are eroded.
<p>
An emblem of a vibrant, participatory democracy is the ability of people 
to develop as individuals, separate and distinct from one another, with the 
confidence to hold and express their own political opinions, beliefs and 
preferences.  A free society tolerates -- even revels in -- such individuality, 
recognizing it as the bedrock of an open society.
<p>
Once divulged, bits of personal information can reveal what we think, 
believe, and feel.  Personal information, disclosed over a period of time in a 
variety of circumstances, can be culled to create a "womb to tomb dossier."  As 
people lose the ability to control how others see them, and judgments are 
made about them based on information gathered third hand, people grow to 
distrust information-gathering entities.  People become reticent to fully 
communicate for fear the information will be used for unintended purposes, 
and they may ultimately lose confidence in their ability to participate in a 
range of traditional and emerging settings.11  Buttressing these conclusions, a 
number of recent polls document peoples' growing concerns that their privacy is increasingly threatened as they lose control over personal information.12
<p>	
In this context, privacy means controlling who can know what about us.  
It means that we, as individuals, can regulate the flow of personal 
information, whether we are alone, in social settings, business transactions 
and, to a less absolute extent, to the government.  The following section is a 
brief review of the current state of privacy law and practice, which will serve 
as the foundation for a proposal for a new privacy paradigm for the 
interactive age. 
<p>
<h3>IV.  CURRENT PRIVACY PARADIGM</h3>
<p>
In the information age, neither prong of the privacy right (to be let 
alone and to control personal information) has developed in law or practice to preserve or advance individual privacy.  In a paper-based, information-
gathering society in which the individual lacks sufficient bargaining power, 
the notice and consent models have failed to provide people with the ability to make meaningful, uncoerced choices about how much personal information to divulge, and how and whether their information can be used for purposes unrelated to those for which it was initially collected. 
<p>
Over the past thirty years, the United States' information privacy policy 
has been loosely and unevenly patched from a series of Supreme Court 
decisions, federal statutes, executive branch reports, and industry self-
regulation.  The Code of Fair Information Practice Principles developed by the 
Department of Health, Education and Welfare in 1973, has served as the basis 
for much of the information privacy legislation and policy in place today.  The central principle is that information collected for one purpose shall not be used for a different purpose without the individual's consent.  The principle is more extensively discussed than it is applied. 
<p>
Even where the private sector has voluntarily adopted such a consent  
principle, it has fallen short of empowering people to make informed, 
uncoerced choices about secondary information use.  Nevertheless, it is fair to 
say that in theory, a general consensus has developed among many privacy 
and consumer groups, the private sector, and even the government, that 
individuals should be informed of and able to make choices about the 
secondary use of personal information.13   The challenge has always been how to craft workable and enforceable mechanisms to put the policy into 
practice.14  With few exceptions, industry representatives argue vigorously 
that "opt-out" must be the maximum privacy mechanism, which means that 
unless an individual affirmatively objects to a secondary use of information, 
the information gatherer is free to reuse and redisclose personal information.  
As privacy advocates have long argued, the opt-out approach places the 
burden of restricting information use on the individual, and thereby creates a 
presumption that ancillary, unrelated uses of personal information are 
acceptable.  Another criticism leveled at the opt-out mechanism is that it 
insufficiently reflects peoples' true privacy values since such a small 
percentage of people actually exercise the option, attributable to a lack of 
notice, fear of negative consequences, and a reluctance to engage in one more 
step beyond what is minimally necessary to complete a transaction.
<p>
Exacerbating the insufficiency of privacy law and practice is the weak 
state of constitutional jurisprudence in the area of information privacy.  In 
one of its seminal privacy cases, U.S. v. Katz,  the Supreme Court ruled that the Fourth Amendment protects "people, not places" from unwarranted searches and seizures.15   In Katz,  the Court found that what a person "seeks to preserve as private, even in an area accessible  to the public, may be 
constitutionally protected" provided the individual has a subjective actual 
expectation of privacy which the society will recognize as reasonable. The 
reasonable expectation is then weighed against the government's interest in 
access, and the extent of the intrusion.
<p>
Although hailed as a landmark privacy decision, the Katz  test has been 
applied in later cases to undermine privacy interests.  In Katz's  progeny, the 
Court has applied the "reasonable expectation" test as a relative standard 
informed by the technological and social realities of the day.  As technology 
has advanced, and as societal demands for sensitive personal information 
have increased, the Court has increasingly circumscribed the "zones" one may justifiably consider private.  Thus in California v. Ciraolo,  the Court held that the use of a fixed-wing aircraft to observe marijuana on defendant's property from 1,000 feet did not violate his protected "zone of privacy" even though he had built a 10-foot fence around his backyard with the intent to shield it from passers-by.16  The Court stated that the defendant's subjective expectation of privacy was not one "that society is prepared to honor … [i]n an age where private and commercial flight in the public airways is routine." 
<p>
Similarly, in California v. Greenwood,  the Court found that people have 
no reasonable expectation of privacy in garbage once it is removed from the 
home and placed on the curb for pick-up, even if a county ordinance requires 
the trash to be placed on the curb and does not allow for disposal in any other 
way.17  The Court reasoned that the defendants deposited their garbage "in an 
area particularly suited for public inspection and … for the express purpose of 
having strangers take it" and could not expect Fourth Amendment protection 
for items they "knowingly expose[d] to the public."  
<p>
The "reasonable expectation" test has proven particularly troublesome in 
the information privacy context.  The Court has continually held that 
individuals have no privacy interest in information divulged to the private 
sector, even though modern society leaves citizens no option but to disclose to others (e.g., disclosure as a condition of participation in society and technology accumulating transactional data). 18
<p>
The distinction is blurring between the content of a communication and 
the transactional data generated in the course of a communication.  In the 
nine years since the enactment of ECPA, society's patterns of using 
communications technologies has changed dramatically.  Millions of people 
have electronic mail addresses; large numbers of businesses, nonprofit and 
political groups conduct their work over the Internet; and use of the World 
Wide Web is exploding.  Detailed information about a person's visits to Usenet and World Wide Web sites are logged, and may be used without a person's knowledge. 
<p>
Records of all of these activities -- who sends a message to whom, where 
a given communications device is located, which political party one contacts 
for information, and which online discussion group or virtual community one associates with -- are available both in real time and in stored form as part of the transactional information generated by advanced computer and 
communications networks.  This transactional information reveals almost as 
much about our private lives as would be learned if someone literally 
followed us around on the street.  
<p>
To varying degrees, people expect that this transactional data is 
"private."  There are content-like characteristics to transactional data that 
require it be afforded a level of legal protection akin to content.  In the past 
year, there has been political consensus in support of raising legal protections 
for such increasingly sensitive and unprotected transaction data.  However, so 
far, the legal limits on access apply only to the government. 
<p>
There is increasing urgency to address the private sector's use of 
transactional data.  The NII Advisory Committee's Privacy Principles and the 
NTIA's recent report both conclude that transaction data is entitled to content-like safeguards from the private sector.
<p>
<h3>IV.   NEW PRIVACY PARADIGM</h3>
<p>
New media presents us with the opportunity to more fully realize 
constitutional privacy principles, while fostering free speech and commerce in the digital environment.  We must build in to the technology and its 
applications the capacity to move beyond "opt-in" and "opt-out" to 
mechanisms of meaningful individual choice. Widespread availability of choice options will also reverse the use of the Katz  standard to undermine privacy protections.  If technology can be a tool for people to more easily manifest their subjective privacy expectations, then those expectations are more likely to be recognized by the society (and the Court) as objectively reasonable. 
<p>
In the interactive sphere, technology may be designed to empower 
individuals to gain greater control over their lives by making decisions about 
the use of their personal information.  Those decisions may vary from 
transaction to transaction, depending upon the nature of the transaction, the 
recipient of the personal information, the offers proffered, and a slew of other 
variables.  For instance, some people consider their address to be sensitive 
information.  Others may be unconcerned about disclosures of their phone 
numbers, ages, salaries, or travel patterns.  In the interactive realm, 
technology has the capacity to be the individual's ally, not the intrusive, 
meglomaniacal villain, as it is often perceived. 
<p>
In fact, both privacy prongs can be more fully addressed by interactive 
technologies that allow people to filter out unwanted communications that 
may come into their home, as well as to make choices about the use of the 
personal information they are divulging.  The Caller ID experience is 
instructive here in that technology can be designed to give people greater 
control over both the information they divulge and receive. 
<p>
Interactive technologies can be designed with features that empower 
individuals to control the flow of information.  The initial point of contact is 
ideal for conveying information about the information practices and policies of an information user to the individual and providing them with the ability to make choices concerning the information use.
<p>
Traditional opt-out/opt-in mechanisms for obtaining consent usually 
involve an "all or nothing" approach.  The ease and economy of interactive 
communications offers an opportunity for more granular levels of choice.  
Information collectors and users can more easily ask specific questions, 
request more detailed information, and tailor their requests and responses.  
To some extent, exercising choice in the use of personal information may 
alleviate the fear of surveillance and abuse that makes many individuals 
reticent about using new technologies.   
<p>
An individual must be given clear and conspicuous (up-front) notice of 
information policies and practices in order to make informed choices about 
information uses.  Transparency, a central principle of fair information 
practices, requires that individuals be told about the information that is being 
collected from them, and how it will be used and disclosed.  Software can be 
designed that allows individuals to access additional information about 
information practices, and to actually see the amount of information they are 
revealing by engaging in a given activity.  
<p>
Choice functions that allow individuals to exercise a number of options 
regarding information flow can be used to gather consent to information use 
and to record limits on information use.  Software can be designed to require 
the individual to take an action prior to engaging in a specific activity.19  
Through such choice mechanisms, information users can educate consumers 
about information flow while empowering individuals to take a more active 
role in controlling the information they release and receive.
<p>
As technology options are explored, a number of difficult questions must 
be resolved.  Who in a particular transaction stream is responsible for 
providing the individual with notice and choice?  Whose notice and choice 
decisions apply to whom? For instance, if an individual is using her America 
Online account to access LL Bean and uses her American Express card to buy 
long johns, which company's choice option applies?  From a privacy and 
business standpoint, should the first choice exercised flow with the rest of the 
transaction or do the entities have a justifiable, independent interest in using 
the personal information for their own secondary uses if they have obtained 
consent in a different context?  Will the individual's privacy preferences vary 
across entities? 
<p>
In addition, agents and contractors of the primary entity (such as 
Federal Express, or a billing company) should not be able to assert an interest 
in using the information beyond the purpose for which it was disclosed.
<p>
<h3>V.   DESIGNING, IMPLEMENTING AND ENFORCING USER EMPOWERING TECHNOLOGIES</h3> 
<p>
Technology that empowers individuals to make choices about the use of 
personal information will benefit consumer privacy and ultimately commerce.  Not only does a more informed, active citizenry breed a robust, participatory democracy, but voluntary, knowledgeable participation in the marketplace will lead to more confident consumers.  The opportunity for entities to establish more direct relationships with the individual can lead to a more refined, detailed, useful awareness of the consumer.  As people gain greater trust in the interactive environment, they will be less reticent to participate.  As segments of the private sector already recognize, allowing people to make decisions about the use of personal information is an essential business practice.  Good privacy practices are crucial to individuals, and necessary to foster free speech and commerce.
<p>
Just as industry, researchers and the public interest community have 
joined together to design technologies to empower people to filter out 
objectionable material on the Internet through the Platform for Internet 
Content Selection (PICS), so too can the PICS model be harnessed or expanded 
to include a privacy focus.  The key distinction between the drive to develop a 
non-regulatory solution in the free speech arena and efforts to devise 
privacy-enhancing technologies is that in the former instance we face the 
serious threat of censorship legislation.  In the privacy arena, the private 
sector has a window of opportunity to be one step ahead of the Congress. 
However, as the NTIA report warned, and privacy advocates will demand, 
meaningful, enforceable privacy guidelines and mechanisms must be put in 
place industry-wide.
<p>
<h3>VI.  NEXT STEPS</h3>
<p>
The Center for Democracy and Technology's Privacy Forum, a consortium 
of public interest and private sector organizations, is in the process of 
identifying and developing privacy models and guidelines for transactional 
data and interactive media. The Forum is convening a series of briefings and 
demonstrations to work towards technical and policy options that allow people to make choices about the use of their personal information and 
communications.  At this early stage, the Forum is identifying the extent to 
which personal information is generated and stored in interactive media.  The goal is to develop a set of privacy "rules of the road" that enhance individual choice, foster free speech and other democratic values, and support the continued development of a vibrant Global Information Infrastructure.
<p>
<p>
<hr size = 2>
<h3>Footnotes</h3>
<p>
<ol>
<li>The Federal Trade Commission has been examining privacy issues and the GII this past year.  The National Information Infrastructure Advisory Council issued  its "Privacy and Security-Related Principles" 
early this year, followed by the inter-agency Information Infrastructure Task Force's Privacy Principles. Most recently, the Department of Commerce's NTIA released its report on "Privacy and Telecommunications-Related Data," which concluded that the private sector must implement privacy standards or face a legislative mandate.
<p>
<li>See , Washington Post, "When Direct Mail Meets E-mail, Privacy Issue  Is Not Fully Addressed," John Schwartz, 10/9/95.   See also, Similarly, public reaction, in Missouri, was so intense to a new product called "Caller Intellidata" that Southwestern Bell withdrew it the day after introduction.  Caller Intellidata packaged Caller ID information, including date and time of call, from Southwestern Bell, with caller address and demographic information compiled by Equifax.  In addition to individual profiles of callers, 
this service would include a statistical profile of the businesses customers based on demographic information from census reports and Equifax.  The Public Counsel for Missouri objected to the service calling it "Big Brother" and stating that "Consumers should not be forced to become statistics in a marketing study merely by placing a telephone call."  St. Louis Dispatch, Jerri Stroud, October 5-6, 1995.
<p>
<li>See ,  Section 207 of the the Communications Assistance and Law Enforcement Act of 1994, providing heightened protections for transactional data. Pub. L. No. 103414, 108 Stat 4279 (1994).
<p>
<li>See NY Times piece by John Markoff on how security flaws on the Internet are hindering  commerce, "Discovery of Internet flaws is setback for On-Line Trade," 10/11/95;  and the Washington Post story that describes peoples' fear of engaging in commerce on the Internet, "Internet's Reach in Society Grows," 10/31/95.
<p> 
<li>See , the Electronic Communications Privacy Act of 1986, 18 U.S.C. §2510 et seq. (1995); the Cable Communications Act od 1984, Pub. L.No. 98-549, 98 Stat 2779 (1984) (codified as amened in scattered sections of 47 U.S.C.); and, the Video Privacy Protection Act of 1988, 18 U.S.C. §2710 (1995).
<p>
<li>October, 1995 report, p.26.
<p>
<li>David Flaherty, reminiscent of Justice Potter Stewart's attempt to define obscenity: "I know it when I see it."
<p>
<li>Alan Westin, Privacy and Freedom, New York, 1967, p. 39.
<p>
<li>See the writings of Erving Goffman, Edward Blaustein and Julie Inness for more discussion of the societal impact of inadequate privacy.
<p>
<li>For a discussion of  legal theories related to the development of "personhood"  and autonomy in society, see Margaret Radin, "Property and Personhood," 34 STANF. L.F. 957 (1982), "The Consequences of Conceptualism," 41 U. MIAMI L.Rev. 239 (1986), "Market-Inalienability," 100 HARV. L.R. 1849 (1987);  and Charles  Reich, "The New Property," 73 YALE LAW J. 733 (1964), "Beyond the New Property," 56 BROOK. L.R. 731 (1990); "The Liberty Impact of the New Property," 31 WM. & MARY L. REV. 295 (1990).
<p>
<li>One need only look at the growth of a health information infrastructure without adequate privacy safeguards that has contributed to the escalating public distrust of doctors and payers ability to maintain confidentiality.
<p>
<li>See recent polls on the public's growing worries over the lack of information privacy, by Louis Harris & Associates,  Time/CNN, Mastercard and the American Civil Liberties Union. 
<p>
<li>See, Personal Privacy in an Information Society:  The report of the Privacy Protection Study Commission, Washington DC, 1977;   Privacy and Related Security Principles for the NII,  Mega-Project III of the National Information Infrastructure Advisory Council, 1995;  Principles for Providing and Using Personal Information,  Report of the Privacy Working Group of the Information Infrastructure Task Force, October, 1995;  and corporate privacy policies, such as those of the  of the Direct Marketing Association, American Express, TRW and the Interactive Services Association.
<p>
<li>See the discussions that preceded enactment of the Video Privacy Protection Act, and the Driver's Privacy Protection Act, as well as the current debate over how to craft strong legal privacy protections for peoples' medical records.
<p>
<li>389 U.S. 347 (1967).  Katz reversed U.S. v.Olmstead, which held that the Fourth Amendment covered only physical places, and thus the warrant requirement did not apply to police wiretaps. 277 U.S. 438 (1928).16476 U.S. 207 (1986). 17486 U.S. 35 (1988)
<p>
<li>In Smith v. Maryland, a case involving pen registers, the Court held that people have no Constitutionally protected interest in the numbers dialed from their homes; and in pen registers, and in a case involving personal bank records, 442 U.S. 735 (1979); US  v.  Miller , the Court found no reasonable 
expectation of privacy in personal information divulged to a third party even though individual had no choice but to divulge, 425 U.S. 345 (1976). Both Smith and Miller were later "overturned" by Congress through enactment of the Electronic Communications privacy Act, and the Right to Financial Privacy Act, statutes that created legally enforceable expectations of privacy.
<p>
<li>Netscape currently uses a pop-up screen to warn individuals about the lack of security of the network prior to allowing them to send a credit card number of other information.  The screen prohibits individual's from 
proceeding until they acknowledge the risk.
</ol>
<p>
<hr size = 2>
Return to the a href = "http://www.cdt.org/">CDT Home page</a>

</body>
</html>
</DOC>